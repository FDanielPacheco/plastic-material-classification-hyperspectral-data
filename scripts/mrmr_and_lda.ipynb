{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08ef25c0",
   "metadata": {},
   "source": [
    "<h1>mRMR and LDA<h1> \n",
    "\n",
    "Authors: \n",
    "- Fábio D. Pacheco, up202502538\n",
    "- Maximino Samarychev, up202107590\n",
    "- Filipe Ramos, up202208996\n",
    "\n",
    "Date: 27/11/2025\n",
    "\n",
    "### Description\n",
    "\n",
    "This notebook is used for the following purposes:\n",
    "- Separates the data into a number of k-folds\n",
    "- Uses the train dataset to apply the mRMR extraction method\n",
    "- Uses the extraction done by mRMR to apply the LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff09ee-8e6a-4dc1-9435-6f8cf0d7cd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide dataset into k-folds\n",
    "#839 samples\n",
    "#7-keyfolds de 120\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def divideKFolds(select_keyfold, keyfolds):\n",
    "    test_fold = keyfolds[select_keyfold]\n",
    "    X_test = test_fold.iloc[:, 1:]\n",
    "    y_test = test_fold.iloc[:, 0]\n",
    "    train_folds = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for i, fold in enumerate(keyfolds):\n",
    "        #print(f\"Fold {i} shape:\", fold.shape)\n",
    "        if(i!= select_keyfold):\n",
    "            X_fold = fold.iloc[:, 1:]\n",
    "            y_fold = fold.iloc[:, 0]\n",
    "            train_folds.append(X_fold)\n",
    "            train_labels.append(y_fold)\n",
    "    \n",
    "    X_train = pd.concat(train_folds, axis = 0)\n",
    "    y_train = pd.concat(train_labels, axis = 0)\n",
    "    \n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "df = pd.read_csv('xtrain.csv')\n",
    "df_labels = pd.read_csv('ytrain.csv')\n",
    "\n",
    "df.iloc[:, 0] = df_labels.iloc[:, 1]\n",
    "\n",
    "keyfolds = [ df.iloc[0: 120, :], df.iloc[120: 240, :], df.iloc[240: 360, :],  df.iloc[360: 480, :], df.iloc[480: 600, :], df.iloc[600: 720, :] , df.iloc[720: 840, :]]\n",
    "\n",
    "\n",
    "select_keyfold = 4\n",
    "\n",
    "X_train, y_train, X_test, y_test = divideKFolds(4, keyfolds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763ff0f5",
   "metadata": {},
   "source": [
    "<h1> Minimun Redundancy Maximum Relevance</h1>\n",
    "\n",
    "<h2>Core Ideas of mRMR</h2>\n",
    "mRMR is based on information theory, specifically Mutual Information (MI)\n",
    "<h3>1-Mutual Information: </h3>\n",
    "For two random discrete variables X and Y:\n",
    "\n",
    "$$I(X;Y) = \\sum_{x \\in \\mathcal{X}} \\sum_{y \\in \\mathcal{Y}} p(x,y) \\log \\left( \\frac{p(x,y)}{p(x)p(y)} \\right)$$\n",
    "\n",
    "<h4>Properties:</h4>\n",
    "<ul>\n",
    "    <li>If I(X;Y) = 0, then the varibles are independent.</li>\n",
    "    <li>For a higher Mutual Information the stronger the dependency.</li>\n",
    "</ul>\n",
    "<h3>2-Maximum Relevance</h3>\n",
    "Let:\n",
    "<ul>\n",
    "    <li>fi = candidate feature</li>\n",
    "    <li>c = class label</li>\n",
    "    <li>S = Selected feature subset</li>\n",
    "    <li>|S| = number of selected features</li>\n",
    "</ul>\n",
    "The relevance of a feature set S to the class is defined as:\n",
    "\n",
    "$$D(S, c) = \\frac{1}{|S|} \\sum_{f_i \\in S} I(f_i; c)$$\n",
    "\n",
    "<h4>Interpretation</h4>\n",
    "<ul>\n",
    "    <li>Measures how informative each feature is about the class.</li>\n",
    "    <li>mRMR aims to maximize this quatity.</li>\n",
    "</ul>\n",
    "\n",
    "<h3>3-Minimum Redundancy</h3>\n",
    "Redundancy measures how much information features share with each other\n",
    "$$R(S) = \\frac{1}{|S|^2} \\sum_{f_i \\in S} \\sum_{f_j \\in S} I(f_i; f_j)$$\n",
    "<h4>Interpretation</h4>\n",
    "<ul>\n",
    " <li>High redundancy means that features are correlated or repetitive</li>\n",
    " <li>mRMR aims to minimize this quatity</li>\n",
    "</ul>\n",
    "<h3>4-mRMR Objective Function</h3>\n",
    "mRMR Combines relevance and redundancy into a single criterion:\n",
    "\n",
    "$$\\max \\left( D(S, c) - R(S) \\right)$$\n",
    "Which expands to:\n",
    "\n",
    "$$\\max \\left( \\frac{1}{|S|} \\sum_{f_i \\in S} I(f_i; c) - \\frac{1}{|S|^2} \\sum_{f_i, f_j \\in S} I(f_i; f_j) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91226b4e-d0dc-40e1-82a0-6bd0075980b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class mRMR:\n",
    "    \"\"\"\n",
    "    Minimum Redundancy Maximum Relevance (mRMR) feature selection\n",
    "    for spectral wavelength data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features=20, method='MID', task='classification'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_features : int\n",
    "            Number of features to select\n",
    "        method : str\n",
    "            'MID' (Mutual Information Difference) or 'MIQ' (Mutual Information Quotient)\n",
    "        task : str\n",
    "            'classification' or 'regression'\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.method = method\n",
    "        self.task = task\n",
    "        self.selected_features_ = []\n",
    "        self.scores_ = []\n",
    "        \n",
    "    def _mutual_information(self, X, y):\n",
    "        \"\"\"Calculate mutual information between features and target\"\"\"\n",
    "        if self.task == 'classification':\n",
    "            return mutual_info_classif(X, y, random_state=42)\n",
    "        else:\n",
    "            return mutual_info_regression(X, y, random_state=42)\n",
    "    \n",
    "    def _calculate_redundancy(self, X, selected_idx, candidate_idx):\n",
    "        \"\"\"Calculate redundancy between candidate feature and selected features\"\"\"\n",
    "        if len(selected_idx) == 0:\n",
    "            return 0\n",
    "        \n",
    "        redundancy = 0\n",
    "        for idx in selected_idx:\n",
    "            # Calculate mutual information between two features\n",
    "            mi = np.corrcoef(X[:, candidate_idx], X[:, idx])[0, 1] ** 2\n",
    "            redundancy += mi\n",
    "        \n",
    "        return redundancy / len(selected_idx)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit mRMR feature selection\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data (wavelengths)\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Target values (plastic names/codes)\n",
    "        \"\"\"\n",
    "        # Convert to numpy arrays\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            feature_names = X.columns\n",
    "            X = X.values\n",
    "        else:\n",
    "            feature_names = [f'Feature_{i}' for i in range(X.shape[1])]\n",
    "        \n",
    "        # Encode target if classification\n",
    "        if self.task == 'classification':\n",
    "            if isinstance(y, pd.Series):\n",
    "                y = y.values\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "        \n",
    "        n_samples, n_total_features = X.shape\n",
    "        \n",
    "        # Calculate relevance (MI between each feature and target)\n",
    "        print(\"Calculating feature relevances...\")\n",
    "        relevance = self._mutual_information(X, y)\n",
    "        \n",
    "        # Start with the feature with maximum relevance\n",
    "        selected_idx = [np.argmax(relevance)]\n",
    "        self.selected_features_ = [feature_names[selected_idx[0]]]\n",
    "        self.scores_.append(relevance[selected_idx[0]])\n",
    "        \n",
    "        \n",
    "        # Iteratively select features\n",
    "        remaining_idx = list(set(range(n_total_features)) - set(selected_idx))\n",
    "        \n",
    "        for i in range(1, self.n_features):\n",
    "            mrmr_scores = np.zeros(len(remaining_idx))\n",
    "            \n",
    "            for j, candidate_idx in enumerate(remaining_idx):\n",
    "                # Calculate relevance\n",
    "                rel = relevance[candidate_idx]\n",
    "                \n",
    "                # Calculate redundancy\n",
    "                red = self._calculate_redundancy(X, selected_idx, candidate_idx)\n",
    "                \n",
    "                # Calculate mRMR score\n",
    "                if self.method == 'MID':\n",
    "                    mrmr_scores[j] = rel - red\n",
    "                else:  # MIQ\n",
    "                    mrmr_scores[j] = rel / (red + 1e-10)\n",
    "            \n",
    "            # Select feature with highest mRMR score\n",
    "            best_idx = np.argmax(mrmr_scores)\n",
    "            selected_feature_idx = remaining_idx[best_idx]\n",
    "            \n",
    "            selected_idx.append(selected_feature_idx)\n",
    "            self.selected_features_.append(feature_names[selected_feature_idx])\n",
    "            self.scores_.append(mrmr_scores[best_idx])\n",
    "            \n",
    "            remaining_idx.pop(best_idx)\n",
    "            \n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform data to selected features only\"\"\"\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X[self.selected_features_]\n",
    "        else:\n",
    "            # Assuming feature names are numeric (wavelengths)\n",
    "            selected_idx = [int(feat.split('_')[1]) if '_' in feat else int(feat) \n",
    "                          for feat in self.selected_features_]\n",
    "            return X[:, selected_idx]\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        return self.transform(X)\n",
    "    \n",
    "    def plot_selected_features(self, wavelengths=None):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        if wavelengths is None:\n",
    "            try:\n",
    "                wavelengths = [float(feat) for feat in self.selected_features_]\n",
    "            except:\n",
    "                wavelengths = range(len(self.selected_features_))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.bar(range(len(self.selected_features_)), self.scores_)\n",
    "        plt.xlabel('Selection Order')\n",
    "        plt.ylabel('mRMR Score')\n",
    "        plt.title('mRMR Scores by Selection Order')\n",
    "        plt.xticks(range(len(self.selected_features_)), \n",
    "                   range(1, len(self.selected_features_) + 1))\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.scatter(wavelengths, self.scores_, s=100, alpha=0.6)\n",
    "        plt.xlabel('Wavelength (nm)')\n",
    "        plt.ylabel('mRMR Score')\n",
    "        plt.title('Selected Wavelengths')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1690361",
   "metadata": {},
   "source": [
    "<h1>Linear Discriminant Analysis </h1>\n",
    "Linear Discriminant Analysis (LDA) is a supervised learning method used for:\n",
    "<ul>\n",
    "<li>Classification</li>\n",
    "<li>Dimension reduction</li>\n",
    "</ul>\n",
    "\n",
    "LDA explicitly uses class labels and tries to find projections that best separate different classes.\n",
    "\n",
    "<h2>Core Idea</h2>\n",
    "LDA seeks a linear projection of the data such that:\n",
    "<ul>\n",
    "<li>Samples from the same class are close together</li>\n",
    "<li>Class means are far apart</li>\n",
    "</ul>\n",
    "\n",
    "In short, it maximizes between-class variance while minimizing within-class variance.\n",
    "\n",
    "<h2>Setup and Notation</h2>\n",
    "<h3>Assume</h3>\n",
    "<ul>\n",
    "<li>Dataset with n samples</li>\n",
    "<li>d-dimensional feature vectors xi ∈ R^d</li>\n",
    "<li>C classes</li>\n",
    "<li>Class k has nk samples</li>\n",
    "</ul>\n",
    "\n",
    "<h4>Definitions:</h4>\n",
    "Class mean:\n",
    "\n",
    "$$\\mu_k = \\frac{1}{n_k} \\sum_{\\mathbf{x}_i \\in C_k} \\mathbf{x}_i$$\n",
    "\n",
    "\n",
    "Global mean:\n",
    "\n",
    "$$\\mu = \\frac{1}{n} \\sum_{i=1}^n \\mathbf{x}_i$$\n",
    "\n",
    "<h3>1-Scatter Matrices</h3>\n",
    "LDA is formulated using scatter matrices rather tan covariance matrices\n",
    "\n",
    "<h4>Within-Class Scatter Matrix</h4>\n",
    "Measures how spread out samples are within each class\n",
    "\n",
    "$$S_W = \\sum_{k=1}^C \\sum_{\\mathbf{x}_i \\in C_k} (\\mathbf{x}_i - \\mu_k)(\\mathbf{x}_i - \\mu_k)^T$$\n",
    "\n",
    "<h4>Between-Class Scatter Matrix</h4>\n",
    "Measures how far class means are from the global mean\n",
    "\n",
    "$$S_B = \\sum_{k=1}^C n_k (\\mu_k - \\mu)(\\mu_k - \\mu)^T$$\n",
    "\n",
    "<h3>2-Optimization Objective <h3>\n",
    "We want a projection vector w that:\n",
    "<ul>\n",
    "<li>Maximizes separation between class means</li>\n",
    "<li>Minimizes variance within classes</li>\n",
    "</ul>\n",
    "This is expressed as a Rayleigh quotient:\n",
    "\n",
    "$$J(\\mathbf{w}) = \\frac{\\mathbf{w}^T S_B \\mathbf{w}}{\\mathbf{w}^T S_W \\mathbf{w}}$$\n",
    "\n",
    "\n",
    "<h3>3-Solution via Generalized Eigenvalue Problem</h3>\n",
    "Maximizing J(w) leads to:\n",
    "\n",
    "$$S_B \\mathbf{w} = \\lambda S_W \\mathbf{w}$$\n",
    "\n",
    "<h3>4-Classification Rule</h3>\n",
    "After projecting:\n",
    "\n",
    "$$\\mathbf{z} = W^T \\mathbf{x}$$\n",
    "\n",
    "Classify using:\n",
    "<ul>\n",
    "<li>Nearest class mean.</li>\n",
    "<li>Or linear discriminant functions:</li>\n",
    "</ul>\n",
    "\n",
    "$$\\delta_k(\\mathbf{x}) = \\mathbf{x}^T \\Sigma^{-1} \\mu_k - \\frac{1}{2} \\mu_k^T \\Sigma^{-1} \\mu_k + \\log \\pi_k$$\n",
    "\n",
    "where πk​ is the class prior.\n",
    "\n",
    "\n",
    "<h2> Sumarizing<h2>\n",
    "LDA finds the linear projections that maximize class separability by maximizing between-class variance relative to within-class variance, leading to a generalized eigenvalue problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d2d49ff-f6a5-48b4-8d76-a57bca0faf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def train_lda_classifier(X, y, scale_data=True):\n",
    "    \"\"\"\n",
    "    Train LDA classifier on the dataset\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : DataFrame or array\n",
    "        Feature data (can be mRMR-selected features or all features)\n",
    "    y : Series or array\n",
    "        Target labels (plastic names/codes)\n",
    "    scale_data : bool\n",
    "        Whether to standardize the data (recommended for LDA)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    lda : LinearDiscriminantAnalysis\n",
    "        Trained LDA model\n",
    "    scaler : StandardScaler or None\n",
    "        Fitted scaler (if scale_data=True)\n",
    "    X_scaled : array\n",
    "        Scaled feature data\n",
    "    y_pred : array\n",
    "        Predictions on the training data\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"LDA CLASSIFIER TRAINING\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Convert to numpy if needed\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_array = X.values\n",
    "    else:\n",
    "        X_array = X\n",
    "    \n",
    "    if isinstance(y, pd.Series):\n",
    "        y_array = y.values\n",
    "    else:\n",
    "        y_array = y\n",
    "    \n",
    "    print(f\"\\nData shape: {X_array.shape}\")\n",
    "    print(f\"Number of samples: {X_array.shape[0]}\")\n",
    "    print(f\"Number of features: {X_array.shape[1]}\")\n",
    "    print(f\"Number of classes: {len(np.unique(y_array))}\")\n",
    "    print(f\"Classes: {np.unique(y_array)}\")\n",
    "    \n",
    "    # Standardize the data\n",
    "    if scale_data:\n",
    "        print(\"\\nStandardizing data...\")\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_array)\n",
    "        print(\"Data standardized (mean=0, std=1)\")\n",
    "    else:\n",
    "        scaler = None\n",
    "        X_scaled = X_array\n",
    "        print(\"\\nUsing original scale (no standardization)\")\n",
    "    \n",
    "    # Train LDA\n",
    "    print(\"\\nTraining LDA classifier...\")\n",
    "    lda = LinearDiscriminantAnalysis()\n",
    "    lda.fit(X_scaled, y_array)\n",
    "    \n",
    "    print(f\"LDA model trained successfully\")\n",
    "    print(f\"Number of LDA components: {lda.n_components}\")\n",
    "    \n",
    "    # Make predictions on training data\n",
    "    y_pred = lda.predict(X_scaled)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_array, y_pred)\n",
    "    \n",
    "    \n",
    "    return lda, scaler, X_scaled, y_pred\n",
    "\n",
    "\n",
    "def predict_lda(lda, X, scaler=None):\n",
    "    \"\"\"\n",
    "    Make predictions using trained LDA model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lda : LinearDiscriminantAnalysis\n",
    "        Trained LDA model\n",
    "    X : DataFrame or array\n",
    "        Feature data to predict\n",
    "    scaler : StandardScaler or None\n",
    "        Fitted scaler from training\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : array\n",
    "        Predicted class labels\n",
    "    probabilities : array\n",
    "        Prediction probabilities for each class\n",
    "    \"\"\"\n",
    "    # Convert to numpy if needed\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_array = X.values\n",
    "    else:\n",
    "        X_array = X\n",
    "    \n",
    "    # Scale if scaler is provided\n",
    "    if scaler is not None:\n",
    "        X_scaled = scaler.transform(X_array)\n",
    "    else:\n",
    "        X_scaled = X_array\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = lda.predict(X_scaled)\n",
    "    probabilities = lda.predict_proba(X_scaled)\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, title=\"Confusion Matrix\"):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array\n",
    "        True labels\n",
    "    y_pred : array\n",
    "        Predicted labels\n",
    "    title : str\n",
    "        Plot title\n",
    "    \"\"\"\n",
    "    #plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = np.unique(y_true)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes,\n",
    "                yticklabels=classes,\n",
    "                cbar_kws={'label': 'Count'})\n",
    "    \n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print per-class accuracy\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        class_accuracy = cm[i, i] / cm[i, :].sum()\n",
    "        print(f\"  {cls}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n",
    "\n",
    "def print_accuracy(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    classes = np.unique(y_true)\n",
    "\n",
    "    print(\"\\nPer-class accuracy:\")\n",
    "    for i, cls in enumerate(classes):\n",
    "        class_accuracy = cm[i, i] / cm[i, :].sum()\n",
    "        print(f\"  {cls}: {class_accuracy:.4f} ({class_accuracy*100:.2f}%)\")\n",
    "\n",
    "def plot_lda_components(lda, X_scaled, y, n_components=2):\n",
    "    \"\"\"\n",
    "    Plot LDA components (projection into LDA space)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lda : LinearDiscriminantAnalysis\n",
    "        Trained LDA model\n",
    "    X_scaled : array\n",
    "        Scaled feature data\n",
    "    y : array\n",
    "        Target labels\n",
    "    n_components : int\n",
    "        Number of components to plot (max 2 for 2D plot)\n",
    "    \"\"\"\n",
    "    X_lda = lda.transform(X_scaled)\n",
    "    \n",
    "    if n_components == 2 and X_lda.shape[1] >= 2:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        classes = np.unique(y)\n",
    "        \n",
    "        for cls in classes:\n",
    "            mask = y == cls\n",
    "            plt.scatter(X_lda[mask, 0], X_lda[mask, 1], \n",
    "                       label=cls, alpha=0.6, s=50)\n",
    "        \n",
    "        plt.xlabel('LD1', fontsize=12)\n",
    "        plt.ylabel('LD2', fontsize=12)\n",
    "        plt.title('LDA Projection (First 2 Components)', fontsize=14, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    elif n_components == 1 or X_lda.shape[1] == 1:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        classes = np.unique(y)\n",
    "        \n",
    "        for cls in classes:\n",
    "            mask = y == cls\n",
    "            plt.hist(X_lda[mask, 0], alpha=0.5, label=cls, bins=20)\n",
    "        \n",
    "        plt.xlabel('LD1', fontsize=12)\n",
    "        plt.ylabel('Frequency', fontsize=12)\n",
    "        plt.title('LDA Projection (1st Component)', fontsize=14, fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_lda_model(lda, X, y, scaler=None):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of LDA model\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lda : LinearDiscriminantAnalysis\n",
    "        Trained LDA model\n",
    "    X : DataFrame or array\n",
    "        Feature data\n",
    "    y : Series or array\n",
    "        True labels\n",
    "    scaler : StandardScaler or None\n",
    "        Fitted scaler\n",
    "    \"\"\"\n",
    "    # Make predictions\n",
    "    predictions, probabilities = predict_lda(lda, X, scaler)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"MODEL EVALUATION\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nAccuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y, predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(y, predictions, title=\"LDA Classification Results\")\n",
    "    \n",
    "    return predictions, probabilities\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ccf7e5-f14d-46bb-9e02-a0762b17fc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Applying mRMR Feature Selection\n",
      "==================================================\n",
      "\n",
      "Calculating feature relevances...\n",
      "Training features: (719, 20)\n",
      "Test features: (120, 20)\n",
      "Selected wavelengths: ['767', '2442', '386', '1655', '389', '780', '785', '361', '1659', '493', '2416', '773', '384', '1653', '766', '367', '784', '2411', '385', '774']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (719, 20)\n",
      "Number of samples: 719\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Fold: \n",
      "0\n",
      "Test Accuracy: 0.4917 (49.17%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.47      0.50      0.48        28\n",
      "         PET       0.48      0.77      0.59        39\n",
      "          PP       0.56      0.41      0.47        37\n",
      "          PS       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.49       120\n",
      "   macro avg       0.38      0.42      0.39       120\n",
      "weighted avg       0.44      0.49      0.45       120\n",
      "\n",
      "\n",
      "==================================================\n",
      "Applying mRMR Feature Selection\n",
      "==================================================\n",
      "\n",
      "Calculating feature relevances...\n",
      "Training features: (719, 20)\n",
      "Test features: (120, 20)\n",
      "Selected wavelengths: ['530', '2249', '361', '853', '1659', '386', '823', '1979', '378', '659', '2352', '852', '384', '1658', '531', '2416', '401', '854', '382', '1667']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (719, 20)\n",
      "Number of samples: 719\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Fold: \n",
      "1\n",
      "Test Accuracy: 0.5917 (59.17%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.52      0.67      0.58        21\n",
      "         PET       0.58      0.88      0.70        51\n",
      "          PP       0.88      0.29      0.44        24\n",
      "          PS       0.62      0.21      0.31        24\n",
      "\n",
      "    accuracy                           0.59       120\n",
      "   macro avg       0.65      0.51      0.51       120\n",
      "weighted avg       0.64      0.59      0.55       120\n",
      "\n",
      "\n",
      "==================================================\n",
      "Applying mRMR Feature Selection\n",
      "==================================================\n",
      "\n",
      "Calculating feature relevances...\n",
      "Training features: (719, 20)\n",
      "Test features: (120, 20)\n",
      "Selected wavelengths: ['531', '2382', '386', '1659', '822', '361', '853', '1997', '384', '717', '2379', '500', '852', '379', '1662', '387', '857', '2447', '389', '789']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (719, 20)\n",
      "Number of samples: 719\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Fold: \n",
      "2\n",
      "Test Accuracy: 0.5750 (57.50%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.39      0.26      0.31        27\n",
      "         PET       0.58      0.96      0.72        45\n",
      "          PP       0.60      0.39      0.47        31\n",
      "          PS       0.88      0.41      0.56        17\n",
      "\n",
      "    accuracy                           0.57       120\n",
      "   macro avg       0.61      0.50      0.52       120\n",
      "weighted avg       0.58      0.57      0.54       120\n",
      "\n",
      "\n",
      "==================================================\n",
      "Applying mRMR Feature Selection\n",
      "==================================================\n",
      "\n",
      "Calculating feature relevances...\n",
      "Training features: (719, 20)\n",
      "Test features: (120, 20)\n",
      "Selected wavelengths: ['534', '2352', '353', '853', '1659', '386', '852', '1997', '389', '720', '2416', '854', '398', '1661', '784', '363', '851', '2312', '433', '379']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (719, 20)\n",
      "Number of samples: 719\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Fold: \n",
      "3\n",
      "Test Accuracy: 0.5833 (58.33%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.42      0.61      0.50        18\n",
      "         PET       0.62      0.85      0.72        47\n",
      "          PP       0.71      0.32      0.44        37\n",
      "          PS       0.54      0.39      0.45        18\n",
      "\n",
      "    accuracy                           0.58       120\n",
      "   macro avg       0.57      0.54      0.53       120\n",
      "weighted avg       0.61      0.58      0.56       120\n",
      "\n",
      "\n",
      "==================================================\n",
      "Applying mRMR Feature Selection\n",
      "==================================================\n",
      "\n",
      "Calculating feature relevances...\n",
      "Training features: (719, 20)\n",
      "Test features: (120, 20)\n",
      "Selected wavelengths: ['853', '361', '1659', '386', '2416', '794', '389', '1997', '852', '387', '1667', '854', '388', '2320', '841', '396', '1649', '784', '395', '1653']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (719, 20)\n",
      "Number of samples: 719\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Fold: \n",
      "4\n",
      "Test Accuracy: 0.4833 (48.33%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.33      0.41      0.37        22\n",
      "         PET       0.46      0.92      0.62        39\n",
      "          PP       0.83      0.30      0.44        33\n",
      "          PS       1.00      0.12      0.21        26\n",
      "\n",
      "    accuracy                           0.48       120\n",
      "   macro avg       0.66      0.44      0.41       120\n",
      "weighted avg       0.66      0.48      0.43       120\n",
      "\n",
      "\n",
      "==================================================\n",
      "Applying mRMR Feature Selection\n",
      "==================================================\n",
      "\n",
      "Calculating feature relevances...\n",
      "Training features: (719, 20)\n",
      "Test features: (120, 20)\n",
      "Selected wavelengths: ['530', '2460', '361', '1601', '794', '386', '1661', '783', '389', '2352', '784', '1655', '384', '449', '1654', '782', '387', '2353', '785', '388']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (719, 20)\n",
      "Number of samples: 719\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Fold: \n",
      "5\n",
      "Test Accuracy: 0.3667 (36.67%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.39      0.18      0.25        38\n",
      "         PET       0.41      0.79      0.54        33\n",
      "          PP       0.24      0.33      0.28        27\n",
      "          PS       1.00      0.09      0.17        22\n",
      "\n",
      "    accuracy                           0.37       120\n",
      "   macro avg       0.51      0.35      0.31       120\n",
      "weighted avg       0.47      0.37      0.32       120\n",
      "\n",
      "\n",
      "==================================================\n",
      "Applying mRMR Feature Selection\n",
      "==================================================\n",
      "\n",
      "Calculating feature relevances...\n",
      "Training features: (720, 20)\n",
      "Test features: (119, 20)\n",
      "Selected wavelengths: ['530', '2352', '386', '1079', '1659', '384', '794', '793', '1962', '365', '792', '2299', '382', '1080', '433', '1662', '379', '789', '2416', '529']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (720, 20)\n",
      "Number of samples: 720\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Fold: \n",
      "6\n",
      "Test Accuracy: 0.5882 (58.82%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.60      0.32      0.42        28\n",
      "         PET       0.56      0.91      0.69        46\n",
      "          PP       0.57      0.50      0.53        24\n",
      "          PS       0.88      0.33      0.48        21\n",
      "\n",
      "    accuracy                           0.59       119\n",
      "   macro avg       0.65      0.52      0.53       119\n",
      "weighted avg       0.63      0.59      0.56       119\n",
      "\n",
      "Fold: 0 Test Accuracy: (49.17%)\n",
      "Fold: 1 Test Accuracy: (59.17%)\n",
      "Fold: 2 Test Accuracy: (57.50%)\n",
      "Fold: 3 Test Accuracy: (58.33%)\n",
      "Fold: 4 Test Accuracy: (48.33%)\n",
      "Fold: 5 Test Accuracy: (36.67%)\n",
      "Fold: 6 Test Accuracy: (58.82%)\n"
     ]
    }
   ],
   "source": [
    "# Aplicação com K-folds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# mRMR\n",
    "# ==========================================\n",
    "\n",
    "df = pd.read_csv('xtrain.csv')\n",
    "df_labels = pd.read_csv('ytrain.csv')\n",
    "\n",
    "df.iloc[:, 0] = df_labels.iloc[:, 1]\n",
    "\n",
    "#Select Keyfolds\n",
    "\n",
    "\n",
    "keyfolds = [ df.iloc[0: 120, :], df.iloc[120: 240, :], df.iloc[240: 360, :],  df.iloc[360: 480, :], df.iloc[480: 600, :], df.iloc[600: 720, :] , df.iloc[720: 840, :]]\n",
    "accuracies = []\n",
    "\n",
    "for i in range(7):\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = divideKFolds(i, keyfolds)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Applying mRMR Feature Selection\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    selector = mRMR(n_features=20, method='MID', task='classification')\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    \n",
    "    print(f\"Training features: {X_train_selected.shape}\")\n",
    "    print(f\"Test features: {X_test_selected.shape}\")\n",
    "    print(f\"Selected wavelengths: {selector.selected_features_}\")\n",
    "    \n",
    "    \n",
    "    # ==========================================\n",
    "    # LDA\n",
    "    # ==========================================\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING LDA ON SELECTED FEATURES\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    lda, scaler, X_train_scaled, y_train_pred = train_lda_classifier(X_train_selected, y_train, scale_data=True)\n",
    "    \n",
    "    y_test_pred, y_test_proba = predict_lda(lda, X_test_selected, scaler)\n",
    "    \n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    accuracies.append(test_accuracy)\n",
    "    print(\"Fold: \")\n",
    "    print(i)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "    print(\"\\nTest Set Classification Report:\")\n",
    "    print(classification_report(y_test, y_test_pred))\n",
    "    \n",
    "    #plot_confusion_matrix(y_test, y_test_pred, title = \"Test Set Results\")\n",
    "    #print_accuracy(y_test, y_test_pred)\n",
    "\n",
    "for i in range(7):\n",
    "    print(\"Fold: \" + str(i) + f\" Test Accuracy: ({accuracies[i]*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb730b9-d3d5-4a79-a37d-a1cd4e891f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating feature relevances...\n",
      "Training features: (839, 20)\n",
      "Test features: (210, 20)\n",
      "Selected wavelengths: ['530', '2382', '386', '1659', '784', '361', '853', '1452', '384', '794', '2416', '525', '1667', '389', '780', '353', '2352', '785', '717', '1661']\n",
      "\n",
      "============================================================\n",
      "TRAINING LDA ON SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "LDA CLASSIFIER TRAINING\n",
      "============================================================\n",
      "\n",
      "Data shape: (839, 20)\n",
      "Number of samples: 839\n",
      "Number of features: 20\n",
      "Number of classes: 4\n",
      "Classes: ['PE' 'PET' 'PP' 'PS']\n",
      "\n",
      "Standardizing data...\n",
      "Data standardized (mean=0, std=1)\n",
      "\n",
      "Training LDA classifier...\n",
      "LDA model trained successfully\n",
      "Number of LDA components: None\n",
      "Test Accuracy: 0.5952 (59.52%)\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          PE       0.53      0.59      0.56        46\n",
      "         PET       0.62      0.87      0.72        75\n",
      "          PP       0.57      0.47      0.52        53\n",
      "          PS       0.80      0.22      0.35        36\n",
      "\n",
      "    accuracy                           0.60       210\n",
      "   macro avg       0.63      0.54      0.54       210\n",
      "weighted avg       0.62      0.60      0.57       210\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Per-class accuracy:\n",
      "  PE: 0.5870 (58.70%)\n",
      "  PET: 0.8667 (86.67%)\n",
      "  PP: 0.4717 (47.17%)\n",
      "  PS: 0.2222 (22.22%)\n"
     ]
    }
   ],
   "source": [
    "# Aplicação com dataset de treino\n",
    "\n",
    "df_X_train = pd.read_csv('xtrain.csv')\n",
    "df_y_train = pd.read_csv('ytrain.csv')\n",
    "\n",
    "df_X_test = pd.read_csv('xtest.csv')\n",
    "df_y_test = pd.read_csv('ytest.csv')\n",
    "\n",
    "X_train = df_X_train.iloc[:, 1:]\n",
    "y_train = df_y_train.iloc[:,1]\n",
    "\n",
    "X_test = df_X_test.iloc[:, 1:]\n",
    "y_test = df_y_test.iloc[:,1]\n",
    "\n",
    "selector = mRMR(n_features=20, method='MID', task='classification')\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "\n",
    "\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "print(f\"Training features: {X_train_selected.shape}\")\n",
    "print(f\"Test features: {X_test_selected.shape}\")\n",
    "print(f\"Selected wavelengths: {selector.selected_features_}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# LDA\n",
    "# ==========================================\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING LDA ON SELECTED FEATURES\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "lda, scaler, X_train_scaled, y_train_pred = train_lda_classifier(X_train_selected, y_train, scale_data=True)\n",
    "\n",
    "y_test_pred, y_test_proba = predict_lda(lda, X_test_selected, scaler)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "accuracies.append(test_accuracy)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(\"\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "plot_confusion_matrix(y_test, y_test_pred, title = \"Test Set Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54b87c4",
   "metadata": {},
   "source": [
    "<h1>Conclusions</h3>\n",
    "The application of mRMR feature combined with LDA for the classification of plastics using hyperspectral data demonstrates that these methods are thoretically sound and practically relevant for a spectral based material discrimination. While mRMR reduces the dimensionality of the spectral data, LDA seeks to maximize class separability in the resulting feature space.Together, these methods provide a structured and interpretable approach for plastic classification.\n",
    "\n",
    "However the Obtained classification results indicate that model performance is strongly influenced by the number of avaliable samples per class.\n",
    "Classes with a larger number of samples exhibit significantly higher classification accuracy. For instance PET with the highest number of samples (316), achieves an accuracy of 86.67.\n",
    "In contrast, PS, which has the smallest number of samples (154), shows a markedly lower accuracy of 22.22%.\n",
    "A similar trend is observed for PE and PP, where intermediate samples sizes correspond to moderate classification performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
