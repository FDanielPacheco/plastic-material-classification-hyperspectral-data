{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d325722",
   "metadata": {},
   "source": [
    "## Comparative Spectral Classification Pipeline\n",
    "\n",
    "Authors: \n",
    "- Fábio D. Pacheco, up202502538\n",
    "\n",
    "Date: 24/11/2025\n",
    "\n",
    "### Description\n",
    "\n",
    "This notebook is used for the following purposes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1fc78",
   "metadata": {},
   "source": [
    "#### Comparative Spectral Classification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Loading bar\n",
    "from tqdm         import tqdm\n",
    "from tqdm_joblib  import tqdm_joblib\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection        import StratifiedKFold, cross_validate, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing          import StandardScaler\n",
    "from sklearn.pipeline               import Pipeline\n",
    "from sklearn.metrics                import accuracy_score, balanced_accuracy_score, precision_recall_fscore_support \n",
    "from sklearn.metrics                import confusion_matrix, classification_report, log_loss\n",
    "from sklearn.preprocessing          import LabelEncoder\n",
    "from sklearn.calibration            import calibration_curve\n",
    "from sklearn.base                   import BaseEstimator, TransformerMixin, clone\n",
    "\n",
    "# Classifiers\n",
    "from sklearn.neighbors              import KNeighborsClassifier\n",
    "from sklearn.svm                    import SVC\n",
    "from sklearn.discriminant_analysis  import LinearDiscriminantAnalysis\n",
    "\n",
    "# Calibration\n",
    "from sklearn.calibration            import CalibratedClassifierCV\n",
    "\n",
    "# Savitzky–Golay\n",
    "from scipy.signal                   import savgol_filter\n",
    "\n",
    "# mRMR\n",
    "from sklearn_mrmr.mrmr              import MRMRFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5544a7",
   "metadata": {},
   "source": [
    "#### Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961afba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape of X:(839, 2151), y:(839, 1)\n",
      "Test  shape of X:(210, 2151), y:(210, 1)\n"
     ]
    }
   ],
   "source": [
    "dataset_dir_path = \"../dataset/\"\n",
    "\n",
    "xtrain_path = dataset_dir_path + \"xtrain.csv\"\n",
    "xtest_path  = dataset_dir_path + \"xtest.csv\"\n",
    "\n",
    "ytrain_path = dataset_dir_path + \"ytrain.csv\"\n",
    "ytest_path  = dataset_dir_path + \"ytest.csv\"\n",
    "\n",
    "if( os.path.exists(xtrain_path) ):  X_train  = pd.read_csv( xtrain_path, index_col=0 )\n",
    "if( os.path.exists(ytrain_path) ):  y_train_ = pd.read_csv( ytrain_path, index_col=0 )\n",
    "if( os.path.exists(xtest_path) ):   X_test   = pd.read_csv( xtest_path, index_col=0 )\n",
    "if( os.path.exists(ytest_path) ):   y_test_  = pd.read_csv( ytest_path, index_col=0 )\n",
    "\n",
    "print(f\"Train shape of X:{X_train.shape}, y:{y_train_.shape}\")\n",
    "print(f\"Test  shape of X:{X_test.shape}, y:{y_test_.shape}\")\n",
    "\n",
    "le = LabelEncoder( )\n",
    "\n",
    "y_train = le.fit_transform( y_train_[\"polymer\"] )\n",
    "y_test  = le.transform( y_test_[\"polymer\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456e973",
   "metadata": {},
   "source": [
    "#### Savitzky–Golay Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea32294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SavitzkyGolayTransformer(BaseEstimator, TransformerMixin):\n",
    "  def __init__(\n",
    "    self, \n",
    "    window_length=15, \n",
    "    polyorder=2, \n",
    "    deriv=0\n",
    "  ):\n",
    "    self.window_length = window_length\n",
    "    self.polyorder = polyorder\n",
    "    self.deriv = deriv\n",
    "\n",
    "  def fit(self, X, y=None):\n",
    "    return self\n",
    "\n",
    "  def transform(self, X):\n",
    "    return savgol_filter(\n",
    "      X,\n",
    "      window_length=self.window_length,\n",
    "      polyorder=self.polyorder,\n",
    "      deriv=self.deriv,\n",
    "      axis=1\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbb387",
   "metadata": {},
   "source": [
    "#### 1.) Preprocessing Selection Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a4174a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:41<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(\n",
    "  n_splits=8, \n",
    "  shuffle=True, \n",
    "  random_state=0\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "  (\"scaler\", StandardScaler()),\n",
    "  (\"sg\", \"passthrough\"),\n",
    "  (\"mrmr\", \"passthrough\"),\n",
    "  (\"pca\", \"passthrough\"),\n",
    "  (\"clf\", KNeighborsClassifier(\n",
    "    n_neighbors=3,\n",
    "    metric=\"euclidean\"\n",
    "  ))\n",
    "])\n",
    "\n",
    "param_grid = [\n",
    "  # None\n",
    "  {\n",
    "    \"sg\":   [\"passthrough\"],\n",
    "    \"mrmr\": [\"passthrough\"],\n",
    "    \"pca\":  [\"passthrough\"],\n",
    "  },\n",
    "\n",
    "  # SG only\n",
    "  {\n",
    "    \"sg\":   [SavitzkyGolayTransformer(polyorder=1)],\n",
    "    \"mrmr\": [\"passthrough\"],\n",
    "    \"pca\":  [\"passthrough\"],\n",
    "  },\n",
    "\n",
    "  # PCA only\n",
    "  {\n",
    "    \"sg\":   [\"passthrough\"],\n",
    "    \"mrmr\": [\"passthrough\"],\n",
    "    \"pca\":  [PCA(n_components=0.99)],\n",
    "  },\n",
    "\n",
    "  # SG + PCA\n",
    "  {\n",
    "    \"sg\":   [SavitzkyGolayTransformer(polyorder=1)],\n",
    "    \"mrmr\": [\"passthrough\"],\n",
    "    \"pca\":  [PCA(n_components=0.99)],\n",
    "  },\n",
    "\n",
    "  # mRMR only\n",
    "  {\n",
    "    \"sg\":   [\"passthrough\"],\n",
    "    \"mrmr\": [MRMRFeatureSelector(n_features_to_select=20, method=\"ftest\")],\n",
    "    \"pca\":  [\"passthrough\"],\n",
    "  },\n",
    "\n",
    "  # SG + mRMR\n",
    "  {\n",
    "    \"sg\":   [SavitzkyGolayTransformer(polyorder=1)],\n",
    "    \"mrmr\": [MRMRFeatureSelector(n_features_to_select=20, method=\"ftest\")],\n",
    "    \"pca\":  [\"passthrough\"],\n",
    "  },\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(\n",
    "  pipeline,\n",
    "  param_grid,\n",
    "  scoring=\"balanced_accuracy\",\n",
    "  cv=cv,\n",
    "  n_jobs=-1,\n",
    "  return_train_score=False\n",
    ")\n",
    "\n",
    "n_candidates = len(param_grid)\n",
    "total_fits = n_candidates * cv.get_n_splits( )\n",
    "with tqdm_joblib(tqdm(desc=\"GridSearch preprocessing\", total=total_fits)):\n",
    "  grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1cc1eccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Max mean\n",
      "{'mrmr': 'passthrough', 'pca': PCA(n_components=0.99), 'sg': SavitzkyGolayTransformer(polyorder=1)}\n",
      "Mean:  0.8471260830027992\n",
      "Std:   0.0375653793833751\n",
      "Fit time mean (s):  3.7591810822486877\n",
      "Fit time std (s):  0.5541723486868213\n",
      "=== Min variance\n",
      "{'mrmr': 'passthrough', 'pca': 'passthrough', 'sg': SavitzkyGolayTransformer(polyorder=1)}\n",
      "Accuracy mean:  0.844730969587949\n",
      "Accuracy std:   0.031527647407635404\n",
      "Fit time mean (s):  0.24008944630622864\n",
      "Fit time std (s):  0.06027216426724537\n"
     ]
    }
   ],
   "source": [
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "cv_results[[\n",
    "  \"mean_test_score\",\n",
    "  \"std_test_score\",\n",
    "  \"param_sg\",\n",
    "  \"param_mrmr\",\n",
    "  \"param_pca\"\n",
    "]].sort_values( \"mean_test_score\", ascending=False )\n",
    "\n",
    "best_stage1 = [ ]\n",
    "best_stage1.append( cv_results.iloc[\n",
    "  cv_results[\"mean_test_score\"].idxmax()\n",
    "])\n",
    "best_stage1.append( cv_results.iloc[\n",
    "  cv_results[\"std_test_score\"].idxmin()\n",
    "])\n",
    "\n",
    "print(\"=== Max mean\")\n",
    "print( best_stage1[0].params )\n",
    "print( \"Mean: \", best_stage1[0].mean_test_score )\n",
    "print( \"Std:  \", best_stage1[0].std_test_score )\n",
    "print( \"Fit time mean (s): \", best_stage1[0].mean_fit_time )\n",
    "print( \"Fit time std (s): \", best_stage1[0].std_fit_time )\n",
    "\n",
    "print(\"=== Min variance\")\n",
    "print( best_stage1[1].params )\n",
    "print( \"Accuracy mean: \", best_stage1[1].mean_test_score )\n",
    "print( \"Accuracy std:  \", best_stage1[1].std_test_score )\n",
    "print( \"Fit time mean (s): \", best_stage1[1].mean_fit_time )\n",
    "print( \"Fit time std (s): \", best_stage1[1].std_fit_time )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fe05b",
   "metadata": {},
   "source": [
    "#### 2.) Preprocessing Hyperparameter Optimization Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8b1be89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GridSearch preprocessing:   0%|          | 0/96 [00:00<?, ?it/s]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [01:51<00:00,  1.16s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "100%|██████████| 32/32 [00:04<00:00,  7.11it/s]\n"
     ]
    }
   ],
   "source": [
    "grids_stage2 = []\n",
    "seen_params  = []\n",
    "unique_best  = []\n",
    "\n",
    "for best in best_stage1:\n",
    "  if best.params not in seen_params:\n",
    "    unique_best.append(best)\n",
    "    seen_params.append(best.params)\n",
    "\n",
    "\n",
    "for best in unique_best:\n",
    "  pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"sg\",    best.params[\"sg\"]),\n",
    "    (\"mrmr\",  best.params[\"mrmr\"]),\n",
    "    (\"pca\",   best.params[\"pca\"]),\n",
    "    (\"clf\",   KNeighborsClassifier(n_neighbors=3, metric=\"euclidean\"))\n",
    "  ])\n",
    "\n",
    "  sg_list = [\"passthrough\"]\n",
    "  if best.params[\"sg\"] != \"passthrough\":\n",
    "    sg_list = [\n",
    "      SavitzkyGolayTransformer(window_length=11, polyorder=1, deriv=0), \n",
    "      SavitzkyGolayTransformer(window_length=11, polyorder=1, deriv=1),\n",
    "      SavitzkyGolayTransformer(window_length=51, polyorder=1, deriv=0),\n",
    "      SavitzkyGolayTransformer(window_length=51, polyorder=1, deriv=1)\n",
    "    ]\n",
    "\n",
    "  mrmr_list = [\"passthrough\"]\n",
    "  if best.params[\"mrmr\"] != \"passthrough\":\n",
    "    mrmr_list = [\n",
    "      MRMRFeatureSelector(n_features_to_select=40, method=\"ftest\"),\n",
    "      MRMRFeatureSelector(n_features_to_select=100, method=\"ftest\"),\n",
    "      MRMRFeatureSelector(n_features_to_select=200, method=\"ftest\")\n",
    "    ]\n",
    "\n",
    "  pca_list = [\"passthrough\"]\n",
    "  if best.params[\"pca\"] != \"passthrough\":\n",
    "    pca_list = [\n",
    "      PCA(n_components=0.95),\n",
    "      PCA(n_components=0.99),\n",
    "      PCA(n_components=0.999)\n",
    "    ]\n",
    "\n",
    "  param_grid = [{\n",
    "    \"sg\": sg_list,\n",
    "    \"mrmr\": mrmr_list,\n",
    "    \"pca\": pca_list,\n",
    "  }]\n",
    "\n",
    "  grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    return_train_score=False\n",
    "  )\n",
    "\n",
    "  n_candidates = len(sg_list) * len(mrmr_list) * len(pca_list)\n",
    "  total_fits = n_candidates * cv.get_n_splits()\n",
    "\n",
    "  with tqdm_joblib( tqdm( desc=\"GridSearch preprocessing\", total=total_fits ) ):\n",
    "    grid.fit( X_train, y_train )\n",
    "\n",
    "  grids_stage2.append( grid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fb2075bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Max mean\n",
      "{'mrmr': 'passthrough', 'pca': PCA(n_components=0.95), 'sg': SavitzkyGolayTransformer(deriv=1, polyorder=1, window_length=51)}\n",
      "Mean:  0.9168467083584361\n",
      "Std:   0.0370828831913902\n",
      "Fit time mean (s):  3.586889773607254\n",
      "Fit time std (s):  0.2549902371621424\n",
      "=== Min variance\n",
      "{'mrmr': 'passthrough', 'pca': PCA(n_components=0.999), 'sg': SavitzkyGolayTransformer(deriv=1, polyorder=1, window_length=51)}\n",
      "Accuracy mean:  0.8570415233387201\n",
      "Accuracy std:   0.020582263293456617\n",
      "Fit time mean (s):  4.909534752368927\n",
      "Fit time std (s):  1.0226899746928908\n",
      "=== Max mean\n",
      "{'mrmr': 'passthrough', 'pca': 'passthrough', 'sg': SavitzkyGolayTransformer(deriv=1, polyorder=1, window_length=51)}\n",
      "Mean:  0.8532400877938635\n",
      "Std:   0.019799229826236945\n",
      "Fit time mean (s):  0.40205472707748413\n",
      "Fit time std (s):  0.29010776412000744\n",
      "=== Min variance\n",
      "{'mrmr': 'passthrough', 'pca': 'passthrough', 'sg': SavitzkyGolayTransformer(deriv=1, polyorder=1, window_length=51)}\n",
      "Accuracy mean:  0.8532400877938635\n",
      "Accuracy std:   0.019799229826236945\n",
      "Fit time mean (s):  0.40205472707748413\n",
      "Fit time std (s):  0.29010776412000744\n"
     ]
    }
   ],
   "source": [
    "best_stage2 = [ ]\n",
    "\n",
    "for grid in grids_stage2: \n",
    "  cv_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "  cv_results[[\n",
    "    \"mean_test_score\",\n",
    "    \"std_test_score\",\n",
    "    \"param_sg\",\n",
    "    \"param_mrmr\",\n",
    "    \"param_pca\"\n",
    "  ]].sort_values( \"mean_test_score\", ascending=False )\n",
    "\n",
    "  opt = []\n",
    "\n",
    "  opt.append( cv_results.iloc[\n",
    "    cv_results[\"mean_test_score\"].idxmax()\n",
    "  ])\n",
    "  opt.append( cv_results.iloc[\n",
    "    cv_results[\"std_test_score\"].idxmin()\n",
    "  ])\n",
    "\n",
    "  best_stage2.append( opt )\n",
    "\n",
    "  print(\"=== Max mean\")\n",
    "  print( opt[0].params )\n",
    "  print( \"Mean: \", opt[0].mean_test_score )\n",
    "  print( \"Std:  \", opt[0].std_test_score )\n",
    "  print( \"Fit time mean (s): \", opt[0].mean_fit_time )\n",
    "  print( \"Fit time std (s): \", opt[0].std_fit_time )\n",
    "\n",
    "  print(\"=== Min variance\")\n",
    "  print( opt[1].params )\n",
    "  print( \"Accuracy mean: \", opt[1].mean_test_score )\n",
    "  print( \"Accuracy std:  \", opt[1].std_test_score )\n",
    "  print( \"Fit time mean (s): \", opt[1].mean_fit_time )\n",
    "  print( \"Fit time std (s): \", opt[1].std_fit_time )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3115fc",
   "metadata": {},
   "source": [
    "#### 3.) Classification Hyperparameter Optimization Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f397d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Comparing Classifiers:   0%|          | 0/8 [01:35<?, ?it/s]\n",
      "Comparing Classifiers:   0%|          | 0/8 [01:20<?, ?it/s]\n",
      "100%|██████████| 8/8 [00:15<00:00,  1.89s/it]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "100%|██████████| 8/8 [00:16<00:00,  2.09s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 8/8 [00:45<00:00,  5.73s/it]\n"
     ]
    }
   ],
   "source": [
    "grids_stage3 = []\n",
    "seen_params  = []\n",
    "unique_best  = []\n",
    "\n",
    "for stage1 in best_stage2:\n",
    "  for best in stage1: \n",
    "    if best.params not in seen_params:\n",
    "      unique_best.append(best)\n",
    "      seen_params.append(best.params)\n",
    "      \n",
    "for best in unique_best:\n",
    "  pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"sg\",    best.params[\"sg\"]),\n",
    "    (\"mrmr\",  best.params[\"mrmr\"]),\n",
    "    (\"pca\",   best.params[\"pca\"]),\n",
    "    (\"clf\",   \"passthrough\") \n",
    "  ])\n",
    "\n",
    "  param_grid = [\n",
    "    # kNN\n",
    "    #{ \n",
    "    #  \"clf\": [KNeighborsClassifier()],\n",
    "    #  \"clf__n_neighbors\": [3, 5, 7, 9],\n",
    "    #  \"clf__metric\": ['euclidean', 'manhattan', 'cosine'],\n",
    "    #  \"clf__weights\": ['uniform', 'distance']\n",
    "    #},\n",
    "\n",
    "    # SVM\n",
    "    {\n",
    "      \"clf\": [SVC(probability=True, decision_function_shape=\"ovo\", class_weight=\"balanced\")],\n",
    "      # \"clf__C\": [1000],\n",
    "      # \"clf__kernel\": [\"linear\"]\n",
    "    },\n",
    "\n",
    "    # LDA\n",
    "    #{\n",
    "    #  \"clf\": [LinearDiscriminantAnalysis()],\n",
    "    #  \"clf__solver\": [\"svd\", \"lsqr\"]\n",
    "    #}\n",
    "  ]\n",
    "\n",
    "  grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    "  )\n",
    "\n",
    "  # Calculate total fits: Sum of combinations in each dict * folds\n",
    "  n_candidates = 0\n",
    "  for pg in param_grid:\n",
    "    combos = 1\n",
    "    for key, values in pg.items():\n",
    "      combos *= len(values)\n",
    "    n_candidates += combos\n",
    "\n",
    "  total_fits = n_candidates * cv.get_n_splits()\n",
    "\n",
    "  with tqdm_joblib(tqdm(desc=f\"Comparing Classifiers\", total=total_fits)):\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "  grids_stage3.append(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "6a88b892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Model preprocessor\n",
      "SG: SavitzkyGolayTransformer(deriv=1, polyorder=1, window_length=51)\n",
      "PCA: PCA(n_components=0.95)\n",
      "mRMR: passthrough\n",
      "=== Max mean\n",
      "{'clf': SVC(probability=True)}\n",
      "Mean:  0.5643046117159389\n",
      "Std:   0.044032038108131714\n",
      "Fit time mean (s):  4.886230647563934\n",
      "Fit time std (s):  0.40615739663878603\n",
      "=== Min variance\n",
      "{'clf': SVC(probability=True)}\n",
      "Accuracy mean:  0.5643046117159389\n",
      "Accuracy std:   0.044032038108131714\n",
      "Fit time mean (s):  4.886230647563934\n",
      "Fit time std (s):  0.40615739663878603\n",
      "\n",
      "====== Model preprocessor\n",
      "SG: SavitzkyGolayTransformer(deriv=1, polyorder=1, window_length=51)\n",
      "PCA: PCA(n_components=0.999)\n",
      "mRMR: passthrough\n",
      "=== Max mean\n",
      "{'clf': SVC(probability=True)}\n",
      "Mean:  0.5696234702241567\n",
      "Std:   0.039878943128092016\n",
      "Fit time mean (s):  5.470881402492523\n",
      "Fit time std (s):  0.6487531539711545\n",
      "=== Min variance\n",
      "{'clf': SVC(probability=True)}\n",
      "Accuracy mean:  0.5696234702241567\n",
      "Accuracy std:   0.039878943128092016\n",
      "Fit time mean (s):  5.470881402492523\n",
      "Fit time std (s):  0.6487531539711545\n",
      "\n",
      "====== Model preprocessor\n",
      "SG: SavitzkyGolayTransformer(deriv=1, polyorder=1, window_length=51)\n",
      "PCA: passthrough\n",
      "mRMR: passthrough\n",
      "=== Max mean\n",
      "{'clf': SVC(probability=True)}\n",
      "Mean:  0.5708253933010798\n",
      "Std:   0.04196194076820246\n",
      "Fit time mean (s):  17.3647323846817\n",
      "Fit time std (s):  1.236828851313436\n",
      "=== Min variance\n",
      "{'clf': SVC(probability=True)}\n",
      "Accuracy mean:  0.5708253933010798\n",
      "Accuracy std:   0.04196194076820246\n",
      "Fit time mean (s):  17.3647323846817\n",
      "Fit time std (s):  1.236828851313436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_stage3 = [ ]\n",
    "\n",
    "for grid in grids_stage3: \n",
    "  cv_results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "  opt = []\n",
    "\n",
    "  opt.append( cv_results.iloc[\n",
    "    cv_results[\"mean_test_score\"].idxmax()\n",
    "  ])\n",
    "  opt.append( cv_results.iloc[\n",
    "    cv_results[\"std_test_score\"].idxmin()\n",
    "  ])\n",
    "\n",
    "  best_stage3.append( opt )\n",
    "\n",
    "  print(\"====== Model preprocessor\")\n",
    "  print(f\"SG: {grid.estimator.named_steps['sg']}\")\n",
    "  print(f\"PCA: {grid.estimator.named_steps['pca']}\")\n",
    "  print(f\"mRMR: {grid.estimator.named_steps['mrmr']}\")\n",
    "\n",
    "  print(\"=== Max mean\")\n",
    "  print( opt[0].params )\n",
    "  print( \"Mean: \", opt[0].mean_test_score )\n",
    "  print( \"Std:  \", opt[0].std_test_score )\n",
    "  print( \"Fit time mean (s): \", opt[0].mean_fit_time )\n",
    "  print( \"Fit time std (s): \", opt[0].std_fit_time )\n",
    "\n",
    "  print(\"=== Min variance\")\n",
    "  print( opt[1].params )\n",
    "  print( \"Accuracy mean: \", opt[1].mean_test_score )\n",
    "  print( \"Accuracy std:  \", opt[1].std_test_score )\n",
    "  print( \"Fit time mean (s): \", opt[1].mean_fit_time )\n",
    "  print( \"Fit time std (s): \", opt[1].std_fit_time )\n",
    "  print( \"\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6981283e",
   "metadata": {},
   "source": [
    "#### Train the best performer models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c1d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_stage3_models = []\n",
    "\n",
    "for i, grid in enumerate(grids_stage3):\n",
    "  cv_results = pd.DataFrame(grid.cv_results_)\n",
    "  \n",
    "  # 1. Capture the Max Mean (Best Estimator is already fitted by GridSearch)\n",
    "  best_stage3_models.append({\n",
    "    \"desc\": f\"Strategy_{i}_Max_Mean\",\n",
    "    \"model\": grid.best_estimator_, \n",
    "    \"score\": grid.best_score_\n",
    "  })\n",
    "  \n",
    "  # 2. Capture the Min Variance (Might be different from Max Mean)\n",
    "  idx_min_var = cv_results[\"std_test_score\"].idxmin( )\n",
    "  best_var_params = cv_results.loc[idx_min_var, \"params\"]\n",
    "  \n",
    "  # Check if it's the same as the best_estimator_ to avoid double work\n",
    "  if idx_min_var != cv_results[\"mean_test_score\"].idxmax():\n",
    "    min_var_model = clone(grid.estimator).set_params(**best_var_params)\n",
    "    min_var_model.fit(X_train, y_train)\n",
    "    \n",
    "    best_stage3_models.append({\n",
    "        \"desc\": f\"Strategy_{i}_Min_Var\",\n",
    "        \"model\": min_var_model,\n",
    "        \"score\": cv_results.loc[idx_min_var, \"mean_test_score\"]\n",
    "    })\n",
    "\n",
    "print(f\"Captured {len(best_stage3_models)} winners.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cd8a09",
   "metadata": {},
   "source": [
    "#### 4.) Calibration with Platt Scaling Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d59c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_results = []\n",
    "\n",
    "for item in best_stage3_models:\n",
    "  base_model = item['model']\n",
    "  name = item['desc']\n",
    "  \n",
    "  # 1. Create the Calibrated version\n",
    "  # We use cv=5 to perform an internal cross-validation for the scaling\n",
    "  calibrated_model = CalibratedClassifierCV(base_model, method='sigmoid', cv=5)\n",
    "  calibrated_model.fit(X_train, y_train)\n",
    "  \n",
    "  calibration_results.append({\n",
    "    \"name\": name,\n",
    "    \"raw_model\": base_model,\n",
    "    \"calibrated_model\": calibrated_model\n",
    "  })\n",
    "\n",
    "print(f\"Calibration complete for {len(calibration_results)} models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
