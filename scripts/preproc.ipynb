{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81f349f8",
   "metadata": {},
   "source": [
    "# Data Pre-Processor\n",
    "\n",
    "Authors: \n",
    "- FÃ¡bio D. Pacheco, up202502538\n",
    "- Maximino Samarychev, up202107590\n",
    "- Filipe Ramos, up202208996\n",
    "\n",
    "Date: 24/11/2025\n",
    "\n",
    "### Description\n",
    "\n",
    "This notebook is used for the following purposes:\n",
    "- Converts the data in .xslx format to .csv\n",
    "- Process the dataset:\n",
    "  - Performs data splice correction \n",
    "  - Compute a single average sample of all pseudo-replicates for the same sample\n",
    "  - Create a labeled dataset\n",
    "- Create a dataset without a 1/64 of the data for test from the Dataset without DC filter, using a random variable, since the samples aint time dependent\n",
    "- Seperate in further datasets for K-fold cross-validation due to the low number of samples on the dataset\n",
    "  - ktrain.csv for train, where k $=1,2,3,...,K$\n",
    "  - kvalid.csv for validation, where k $=1,2,3,...,K$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326bf529",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d05e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: ../dataset/dataset.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl as pyxl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "dataset_dir_path = \"../dataset/\"\n",
    "dataset_path = dataset_dir_path + \"dataset.xlsx\"\n",
    "\n",
    "print(f\"Dataset path: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabb3032",
   "metadata": {},
   "source": [
    "### Data Conversion (from .xslx to .csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a8384bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if( os.path.exists(dataset_path) ):\n",
    "  metadata_dataset = pd.read_excel( dataset_path, sheet_name=1 )\n",
    "  metadata_dataset.to_csv( dataset_dir_path + \"metadata.csv\", index=None, header=True )\n",
    "\n",
    "  raw_dataset = pd.read_excel( dataset_path, sheet_name=2 )\n",
    "  raw_dataset = (\n",
    "    raw_dataset\n",
    "      .drop(columns=['Unnamed: 0'])\n",
    "      .rename(columns={'Unnamed: 1': 'wavelength'})\n",
    "      .set_index('wavelength')\n",
    "  )\n",
    "  raw_dataset.to_csv(dataset_dir_path + \"raw.csv\", index=True, header=True)\n",
    "else:\n",
    "  print(f\"No such dataset at path {dataset_path} ...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c54f03",
   "metadata": {},
   "source": [
    "### Load the raw and metadata files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4ad57051",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path      = dataset_dir_path + \"raw.csv\"\n",
    "metadata_path = dataset_dir_path + \"metadata.csv\"\n",
    "\n",
    "if( os.path.exists(dataset_path) ):\n",
    "  metadata = pd.read_csv( metadata_path )\n",
    "  raw = pd.read_csv(raw_path, index_col=0)\n",
    "\n",
    "raw.columns = raw.columns.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a3936",
   "metadata": {},
   "source": [
    "### Verify the dataset:\n",
    "The values should be inside the interval: $[0, 1]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0583f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with at least one value outside [0,1]: 2151\n",
      "Total entries outside [0,1]: 670735\n"
     ]
    }
   ],
   "source": [
    "stats = raw.describe( )\n",
    "\n",
    "outside_mask = (raw < 0) | (raw > 1)\n",
    "\n",
    "# Count how many entries are outside [0,1] per row\n",
    "outside_per_row = outside_mask.sum(axis=1)\n",
    "\n",
    "# Count how many rows have at least one value outside [0,1]\n",
    "rows_with_outside = (outside_per_row > 0).sum()\n",
    "\n",
    "# Count total number of entries outside [0,1]\n",
    "total_outside = outside_mask.sum( ).sum( )\n",
    "\n",
    "print(f\"Rows with at least one value outside [0,1]: {rows_with_outside}\")\n",
    "print(f\"Total entries outside [0,1]: {total_outside}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626ada82",
   "metadata": {},
   "source": [
    "### Average Pseudo-Replicate Samples and Remove Calibration Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea24647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available polymers\n",
    "polymer_map = {\n",
    "  'polyethylene terephthalate (PET)': 'Polyethylene terephthalate (PET)',\n",
    "  'Polyethylene terephthalate (PET)': 'Polyethylene terephthalate (PET)',\n",
    "  'Polypropylene (PP)': 'Polypropylene (PP)',\n",
    "  'PP': 'Polypropylene (PP)',\n",
    "  'Polyethylene (PE)': 'Polyethylene (PE)',\n",
    "  'PE': 'Polyethylene (PE)',\n",
    "  'Polystyrene (PS)': 'Polystyrene (PS)',\n",
    "  'Extruded polystyrene': 'Polystyrene (PS)',\n",
    "  'PVC': 'Polyvinylchloride (PVC)',\n",
    "  'polyvinylchloride (PVC)': 'Polyvinylchloride (PVC)',\n",
    "  'Thermoplastic elastomer': 'Thermoplastic elastomer',\n",
    "  'Paraffin': 'Paraffin',\n",
    "  'Fluorocarbon': 'Fluorocarbon',\n",
    "  'polyamide (nylon)': 'Polyamide (Nylon)',\n",
    "  'Unknown': 'Unknown'\n",
    "}\n",
    "\n",
    "calibrationSamples = [ \n",
    "  \"White_reference \", \n",
    "  \"Water_16_sediment\", \n",
    "  \"Wood_d_NA_NA_PoA_field\", \n",
    "  \"Clear water\" , \n",
    "  \"Water_1500_algae\", \n",
    "  \"Water_3000_algae\", \n",
    "  \"Water_4_sediment\", \n",
    "  \"Black_cloth_calibrationFacility\"\n",
    "]\n",
    "\n",
    "# List of polymers to keep\n",
    "top_polymers = {\n",
    "  'pet':'Polyethylene terephthalate (PET)',\n",
    "  'pp' :'Polypropylene (PP)',\n",
    "  'pe' :'Polyethylene (PE)',\n",
    "  'ps' :'Polystyrene (PS)'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb0955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the exported matrix is (2151, 1069)\n",
      "            Polypropylene (PP)  Polystyrene (PS)  \\\n",
      "wavelength                                         \n",
      "350                   0.279895          0.080851   \n",
      "351                   0.279861          0.082573   \n",
      "352                   0.277043          0.072646   \n",
      "353                   0.281552          0.070177   \n",
      "354                   0.280615          0.074625   \n",
      "\n",
      "            Polyethylene terephthalate (PET)  \\\n",
      "wavelength                                     \n",
      "350                                 0.349557   \n",
      "351                                 0.354230   \n",
      "352                                 0.356104   \n",
      "353                                 0.356454   \n",
      "354                                 0.359986   \n",
      "\n",
      "            Polyethylene terephthalate (PET)  Polyethylene (PE)  \\\n",
      "wavelength                                                        \n",
      "350                                 0.037285           0.366505   \n",
      "351                                 0.042852           0.367962   \n",
      "352                                 0.042447           0.369270   \n",
      "353                                 0.039856           0.362402   \n",
      "354                                 0.039127           0.361526   \n",
      "\n",
      "            Polystyrene (PS)  Thermoplastic elastomer  Polyethylene (PE)  \\\n",
      "wavelength                                                                 \n",
      "350                 0.326906                 0.096193           0.084466   \n",
      "351                 0.328180                 0.100655           0.085405   \n",
      "352                 0.327552                 0.095508           0.087082   \n",
      "353                 0.324515                 0.093570           0.081840   \n",
      "354                 0.320728                 0.095025           0.080086   \n",
      "\n",
      "            Polypropylene (PP)  Polyethylene (PE)  ...  \\\n",
      "wavelength                                         ...   \n",
      "350                   0.036953           0.107822  ...   \n",
      "351                   0.035038           0.116364  ...   \n",
      "352                   0.036896           0.113345  ...   \n",
      "353                   0.036304           0.112698  ...   \n",
      "354                   0.036467           0.114713  ...   \n",
      "\n",
      "            Polyethylene terephthalate (PET)  \\\n",
      "wavelength                                     \n",
      "350                                 0.024404   \n",
      "351                                 0.030841   \n",
      "352                                 0.037241   \n",
      "353                                 0.040457   \n",
      "354                                 0.032641   \n",
      "\n",
      "            Polyethylene terephthalate (PET)  \\\n",
      "wavelength                                     \n",
      "350                                 0.027838   \n",
      "351                                 0.031171   \n",
      "352                                 0.032264   \n",
      "353                                 0.033850   \n",
      "354                                 0.030562   \n",
      "\n",
      "            Polyethylene terephthalate (PET)  \\\n",
      "wavelength                                     \n",
      "350                                 0.025684   \n",
      "351                                 0.022298   \n",
      "352                                 0.027695   \n",
      "353                                 0.031644   \n",
      "354                                 0.031706   \n",
      "\n",
      "            Polyethylene terephthalate (PET)  Polypropylene (PP)  \\\n",
      "wavelength                                                         \n",
      "350                                 0.046993            0.073646   \n",
      "351                                 0.051425            0.078289   \n",
      "352                                 0.048498            0.081376   \n",
      "353                                 0.044269            0.078006   \n",
      "354                                 0.041328            0.071999   \n",
      "\n",
      "            Polypropylene (PP)  Polypropylene (PP)  Polypropylene (PP)  \\\n",
      "wavelength                                                               \n",
      "350                   0.020904            0.014957            0.025049   \n",
      "351                   0.026739            0.021408            0.025575   \n",
      "352                   0.023306            0.034075            0.027763   \n",
      "353                   0.025792            0.030098            0.030832   \n",
      "354                   0.028038            0.024897            0.025317   \n",
      "\n",
      "            Polypropylene (PP)  Polypropylene (PP)  \n",
      "wavelength                                          \n",
      "350                   0.017847            0.031857  \n",
      "351                   0.019325            0.036187  \n",
      "352                   0.028086            0.036911  \n",
      "353                   0.028121            0.034356  \n",
      "354                   0.024294            0.034569  \n",
      "\n",
      "[5 rows x 1069 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exclude calibration samples while ensuring same index as raw.columns\n",
    "valid = ~metadata['Sample code'].isin(calibrationSamples)\n",
    "\n",
    "# Create group ID: increments at each new pseudo-replicate sequence\n",
    "group_id = metadata['Pseudo-replicates'].eq( 1 ).cumsum( )\n",
    "\n",
    "# Filter to valid columns\n",
    "group_id_valid = group_id[valid]\n",
    "\n",
    "# Compute mean across pseudo-replicates\n",
    "raw_valid = raw.loc[:, valid]\n",
    "mean_samples = raw_valid.T.groupby(group_id_valid).mean( ).T\n",
    "\n",
    "# Get the label for the sample\n",
    "metadata_valid = metadata.loc[valid].copy( )\n",
    "\n",
    "# Define a function to get polymer type from multiple sources\n",
    "def get_polymer_type(row):\n",
    "  for col in ['Polymer identified via microFTIR', 'EMODnet micro-litter polymer type', 'Polymer commercial labeling ']:\n",
    "    if pd.notna(row[col]) and row[col] != 'ND':\n",
    "        return row[col]\n",
    "    \n",
    "  if pd.notna(row['Sample code']) and row['Sample code'] != 'ND':\n",
    "    code = row['Sample code'].lower()\n",
    "    if 'pp' in code:\n",
    "      return 'Polypropylene (PP)'\n",
    "    elif 'pe' in code:\n",
    "      return 'Polyethylene (PE)'\n",
    "    elif 'ps' in code:\n",
    "      return 'Polystyrene (PS)'\n",
    "    elif 'pet' in code:\n",
    "      return 'Polyethylene terephthalate (PET)'\n",
    "  return 'Unknown'\n",
    "\n",
    "# Apply function to valid metadata\n",
    "metadata_valid['polymer_type_final'] = metadata_valid.apply(get_polymer_type, axis=1)\n",
    "\n",
    "# Map each pseudo-replicate group to its polymer type using the first occurrence in each group (all replicates in a group are same polymer)\n",
    "group_polymer = metadata_valid.groupby(group_id_valid)['polymer_type_final'].first()\n",
    "\n",
    "# Assign polymer type to mean_samples\n",
    "mean_samples_polymer = mean_samples.copy( )\n",
    "\n",
    "# Map group IDs to polymer types\n",
    "polymer_names = [group_polymer[i] for i in mean_samples_polymer.columns]\n",
    "\n",
    "# Normalize polymer names\n",
    "mean_samples_polymer.columns = [polymer_map.get(name, 'Unknown') for name in polymer_names]\n",
    "\n",
    "print(f\"The size of the exported matrix is {mean_samples_polymer.shape}\")\n",
    "print( mean_samples_polymer.head( 5 ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285255a3",
   "metadata": {},
   "source": [
    "### Export the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d12d8ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_samples_polymer.to_csv( dataset_dir_path + \"ready_dataset.csv\", index=True, header=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033f5c72",
   "metadata": {},
   "source": [
    "### Statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62cbe322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polyethylene terephthalate (PET)    375\n",
      "Polypropylene (PP)                  266\n",
      "Polyethylene (PE)                   228\n",
      "Polystyrene (PS)                    180\n",
      "Polyvinylchloride (PVC)              11\n",
      "Unknown                               3\n",
      "Thermoplastic elastomer               2\n",
      "Paraffin                              2\n",
      "Fluorocarbon                          1\n",
      "Polyamide (Nylon)                     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dataset_path = dataset_dir_path + \"ready_dataset.csv\"\n",
    "\n",
    "if( os.path.exists(dataset_path) ):\n",
    "  dataset = pd.read_csv( dataset_path, index_col=0 )\n",
    "\n",
    "# Extract the base polymer name (remove any suffix like .1, .2, etc.)\n",
    "# And count the occurrences of each polymer type\n",
    "base_polymers = dataset.columns.str.replace(r\"\\..*$\", \"\", regex=True)\n",
    "polymer_counts = base_polymers.value_counts()\n",
    "\n",
    "print(polymer_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ea931c",
   "metadata": {},
   "source": [
    "### Data division \n",
    "\n",
    "Based on the number of samples available for each polymer, the following were chosen for classification:\n",
    "- PET, PP, PE and PS  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b119063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PET shape: (2151, 375)\n",
      "PP shape: (2151, 266)\n",
      "PE shape: (2151, 228)\n",
      "PS shape: (2151, 180)\n",
      "Classification shape: (2151, 1049)\n",
      "X_train shape: (839, 2151)\n",
      "X_test shape: (210, 2151)\n",
      "polymer\n",
      "PET    300\n",
      "PP     213\n",
      "PE     182\n",
      "PS     144\n",
      "Name: count, dtype: int64\n",
      "polymer\n",
      "PET    75\n",
      "PP     53\n",
      "PE     46\n",
      "PS     36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pet = dataset[[col for col in dataset.columns if col.startswith(top_polymers['pet'])]]\n",
    "pp  = dataset[[col for col in dataset.columns if col.startswith(top_polymers['pp'])]]\n",
    "pe  = dataset[[col for col in dataset.columns if col.startswith(top_polymers['pe'])]]\n",
    "ps  = dataset[[col for col in dataset.columns if col.startswith(top_polymers['ps'])]]\n",
    "\n",
    "# Combine into one dataset\n",
    "dataset_classification = pd.concat([pet, pp, pe, ps], axis=1)\n",
    "\n",
    "# Check shapes\n",
    "print(\"PET shape:\", pet.shape)\n",
    "print(\"PP shape:\", pp.shape)\n",
    "print(\"PE shape:\", pe.shape)\n",
    "print(\"PS shape:\", ps.shape)\n",
    "print(\"Classification shape:\", dataset_classification.shape)\n",
    "\n",
    "# Create labels for each column (sample)\n",
    "labels = []\n",
    "for col in dataset_classification.columns:\n",
    "  for key, val in top_polymers.items():\n",
    "    if col.startswith(val):\n",
    "      labels.append(key.upper())\n",
    "      break\n",
    "\n",
    "# Transpose so that samples are rows\n",
    "dataset_classification = dataset_classification.T\n",
    "dataset_classification['polymer'] = labels\n",
    "\n",
    "# Separate features and labels\n",
    "X = dataset_classification.drop(columns=['polymer'])\n",
    "y = dataset_classification['polymer']\n",
    "\n",
    "# Stratified train/test split\n",
    "X_train, X_test, y_train, y_test = sk.model_selection.train_test_split(\n",
    "  X, y,\n",
    "  test_size=0.2,      # 20% test set\n",
    "  stratify=y,         # maintain polymer distribution\n",
    "  random_state=42\n",
    ")\n",
    "\n",
    "# Check shapes and distribution\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(y_train.value_counts( ))\n",
    "print(y_test.value_counts( ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b08b1",
   "metadata": {},
   "source": [
    "### Export the data ready for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2d07fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data\n",
    "X_train.to_csv( dataset_dir_path + \"xtrain.csv\", index=True, header=True )\n",
    "X_test.to_csv ( dataset_dir_path + \"xtest.csv\" , index=True, header=True )\n",
    "y_train.to_csv( dataset_dir_path + \"ytrain.csv\", index=True, header=True )\n",
    "y_test.to_csv ( dataset_dir_path + \"ytest.csv\" , index=True, header=True )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
